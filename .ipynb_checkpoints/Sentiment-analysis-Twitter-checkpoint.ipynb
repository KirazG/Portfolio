{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Breitbart vs. The Onion: predicting who tweeted what\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"http://cdn.someecards.com/someecards/usercards/1279906132319_9016369.png\">\n",
    "</p>\n",
    "</img>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I mean, you'd think a human would be able to pretty quickly tell the difference between Breitbart and The Onion, but\n",
    "\n",
    "1. are you sure? Every time? The Onion is really good at its job sometimes, and \n",
    "2. even if you can, can your machine?\n",
    "\n",
    "It's not exactly the foremost question of our time, but it makes for a fun afternoon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection \n",
    "\n",
    "I used the [Python Twitter Tools](http://mike.verdone.ca/twitter/) library to collect data from [@BreitbartNews](http://twitter.com/BreitbartNews) and [@TheOnion](http://twitter.com/TheOnion). \n",
    "\n",
    "You can read the documentation on the various data structures you can work with [here](https://python-twitter.readthedocs.io/en/latest/models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter, re, datetime, pandas as pd\n",
    "\n",
    "class twitterminer():\n",
    "\n",
    "    request_limit   =   20    \n",
    "    api             =   False\n",
    "    data            =   []\n",
    "    \n",
    "    twitter_keys = {\n",
    "        'consumer_key':        '', #insert your own twitter keys here\n",
    "        'consumer_secret':     '',\n",
    "        'access_token_key':    '',\n",
    "        'access_token_secret': ''\n",
    "    }\n",
    "    \n",
    "    def __init__(self,  request_limit = 20):\n",
    "        \n",
    "        self.request_limit = request_limit\n",
    "        \n",
    "        self.set_api()\n",
    "        \n",
    "    def set_api(self):\n",
    "        \n",
    "        self.api = twitter.Api(\n",
    "            consumer_key         =   self.twitter_keys['consumer_key'],\n",
    "            consumer_secret      =   self.twitter_keys['consumer_secret'],\n",
    "            access_token_key     =   self.twitter_keys['access_token_key'],\n",
    "            access_token_secret  =   self.twitter_keys['access_token_secret']\n",
    "        )\n",
    "\n",
    "    def mine_user_tweets(self, user=\"\"):\n",
    "\n",
    "        statuses   =   self.api.GetUserTimeline(screen_name=user, count=self.request_limit, include_rts=False)\n",
    "        data       =   []\n",
    "        \n",
    "        for item in statuses:\n",
    "\n",
    "            mined = {\n",
    "                'tweet_id': item.id,\n",
    "                'handle': item.user.name,\n",
    "                'retweet_count': item.retweet_count,\n",
    "                'text': item.text,\n",
    "                'mined_at': datetime.datetime.now(),\n",
    "                'created_at': item.created_at,\n",
    "            }\n",
    "            \n",
    "            data.append(mined)\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's get the first thousand tweets from both accounts\n",
    "miner = twitterminer(request_limit = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a new dataframe with tweets by The Onion\n",
    "onion_tweets = miner.mine_user_tweets(\"TheOnion\")\n",
    "onion_tweets = pd.DataFrame(onion_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon Jan 30 16:53:00 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-01-30 11:54:31.522798</td>\n",
       "      <td>3</td>\n",
       "      <td>The Week In Pictures â€“ Week Of January 30, 201...</td>\n",
       "      <td>826110981025779712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mon Jan 30 16:16:04 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-01-30 11:54:31.522808</td>\n",
       "      <td>42</td>\n",
       "      <td>Finland Aims To Be Tobacco-Free By 2020 https:...</td>\n",
       "      <td>826101685491752963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon Jan 30 15:39:04 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-01-30 11:54:31.522812</td>\n",
       "      <td>233</td>\n",
       "      <td>Man Dying From Cancer Spends Last Good Day On ...</td>\n",
       "      <td>826092371255386113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Jan 30 14:48:06 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-01-30 11:54:31.522815</td>\n",
       "      <td>219</td>\n",
       "      <td>Parents Seize Creative Control Of 3rd-Grade Ar...</td>\n",
       "      <td>826079548089458690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mon Jan 30 13:57:03 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-01-30 11:54:31.522818</td>\n",
       "      <td>395</td>\n",
       "      <td>Slow-Witted Conspiracy Theorist Convinced Gove...</td>\n",
       "      <td>826066701460582400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at     handle                   mined_at  \\\n",
       "0  Mon Jan 30 16:53:00 +0000 2017  The Onion 2017-01-30 11:54:31.522798   \n",
       "1  Mon Jan 30 16:16:04 +0000 2017  The Onion 2017-01-30 11:54:31.522808   \n",
       "2  Mon Jan 30 15:39:04 +0000 2017  The Onion 2017-01-30 11:54:31.522812   \n",
       "3  Mon Jan 30 14:48:06 +0000 2017  The Onion 2017-01-30 11:54:31.522815   \n",
       "4  Mon Jan 30 13:57:03 +0000 2017  The Onion 2017-01-30 11:54:31.522818   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              3  The Week In Pictures â€“ Week Of January 30, 201...   \n",
       "1             42  Finland Aims To Be Tobacco-Free By 2020 https:...   \n",
       "2            233  Man Dying From Cancer Spends Last Good Day On ...   \n",
       "3            219  Parents Seize Creative Control Of 3rd-Grade Ar...   \n",
       "4            395  Slow-Witted Conspiracy Theorist Convinced Gove...   \n",
       "\n",
       "             tweet_id  \n",
       "0  826110981025779712  \n",
       "1  826101685491752963  \n",
       "2  826092371255386113  \n",
       "3  826079548089458690  \n",
       "4  826066701460582400  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onion_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#and another with Breitbart tweets\n",
    "breitbart_tweets = miner.mine_user_tweets(\"BreitbartNews\")\n",
    "breitbart_tweets = pd.DataFrame(breitbart_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon Jan 30 16:47:01 +0000 2017</td>\n",
       "      <td>Breitbart News</td>\n",
       "      <td>2017-01-30 11:54:35.601077</td>\n",
       "      <td>56</td>\n",
       "      <td>Can't Chill the Mill! https://t.co/QZJHj9Pif7</td>\n",
       "      <td>826109473156689921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mon Jan 30 16:20:49 +0000 2017</td>\n",
       "      <td>Breitbart News</td>\n",
       "      <td>2017-01-30 11:54:35.601087</td>\n",
       "      <td>224</td>\n",
       "      <td>Maybe start worrying about your own citizens i...</td>\n",
       "      <td>826102879287128064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon Jan 30 15:53:43 +0000 2017</td>\n",
       "      <td>Breitbart News</td>\n",
       "      <td>2017-01-30 11:54:35.601092</td>\n",
       "      <td>65</td>\n",
       "      <td>Thanks for reading! ðŸ‘‹ https://t.co/j2m76LDglc</td>\n",
       "      <td>826096060888150017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Jan 30 15:40:30 +0000 2017</td>\n",
       "      <td>Breitbart News</td>\n",
       "      <td>2017-01-30 11:54:35.601095</td>\n",
       "      <td>109</td>\n",
       "      <td>Here we go. https://t.co/P3QDUNqz3V</td>\n",
       "      <td>826092732875669505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mon Jan 30 15:23:03 +0000 2017</td>\n",
       "      <td>Breitbart News</td>\n",
       "      <td>2017-01-30 11:54:35.601097</td>\n",
       "      <td>213</td>\n",
       "      <td>Keep calling everyone Nazis and hope for the b...</td>\n",
       "      <td>826088340537692162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at          handle                   mined_at  \\\n",
       "0  Mon Jan 30 16:47:01 +0000 2017  Breitbart News 2017-01-30 11:54:35.601077   \n",
       "1  Mon Jan 30 16:20:49 +0000 2017  Breitbart News 2017-01-30 11:54:35.601087   \n",
       "2  Mon Jan 30 15:53:43 +0000 2017  Breitbart News 2017-01-30 11:54:35.601092   \n",
       "3  Mon Jan 30 15:40:30 +0000 2017  Breitbart News 2017-01-30 11:54:35.601095   \n",
       "4  Mon Jan 30 15:23:03 +0000 2017  Breitbart News 2017-01-30 11:54:35.601097   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0             56      Can't Chill the Mill! https://t.co/QZJHj9Pif7   \n",
       "1            224  Maybe start worrying about your own citizens i...   \n",
       "2             65     Thanks for reading! ðŸ‘‹ https://t.co/j2m76LDglc   \n",
       "3            109                Here we go. https://t.co/P3QDUNqz3V   \n",
       "4            213  Keep calling everyone Nazis and hope for the b...   \n",
       "\n",
       "             tweet_id  \n",
       "0  826109473156689921  \n",
       "1  826102879287128064  \n",
       "2  826096060888150017  \n",
       "3  826092732875669505  \n",
       "4  826088340537692162  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breitbart_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'https co csf5qubhed https co', 4),\n",
       " (u'visit https co csf5qubhed https', 4),\n",
       " (u'complete coverage of the last', 2),\n",
       " (u'americans most physically active when', 2),\n",
       " (u'of secretary of state john', 2),\n",
       " (u'fun activity he signed up', 2),\n",
       " (u'shotgunning brewhas with diamond joe', 2),\n",
       " (u'excruciating torment he experiences at', 2),\n",
       " (u'secretary of state john kerry', 2),\n",
       " (u'experiences at every moment https', 2)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How similar do the ngrams for both accounts look?\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "vect = TfidfVectorizer(ngram_range=(5,5))\n",
    "\n",
    "summaries = \"\".join(onion_tweets['text'])\n",
    "ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "\n",
    "Counter(ngrams_summaries).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'in 877 240 1776 gt', 6),\n",
       " (u'with gehrig38 call in 877', 6),\n",
       " (u'whatever it takes with gehrig38', 6),\n",
       " (u'gehrig38 call in 877 240', 6),\n",
       " (u'call in 877 240 1776', 6),\n",
       " (u'240 1776 gt https co', 6),\n",
       " (u'takes with gehrig38 call in', 6),\n",
       " (u'it takes with gehrig38 call', 6),\n",
       " (u'877 240 1776 gt https', 6),\n",
       " (u'hour two whatever it takes', 3)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer(ngram_range=(5,5))\n",
    "\n",
    "summaries = \"\".join(breitbart_tweets['text'])\n",
    "ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "\n",
    "Counter(ngrams_summaries).most_common(10)\n",
    "\n",
    "#not too similar, so that probably bodes well if we're training an algorithm to tell them apart\n",
    "#there's a tonne of numbers/handles in the Breitbart tweets, but when I googled them, they're all Curt Schilling\n",
    "#promoting Dinesh D'Souza. Should be okay to leave that in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#okay, let's concat the two dataframes so we can work with tweets from both accounts \n",
    "all_tweets = pd.concat([onion_tweets, breitbart_tweets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the data\n",
    "\n",
    "The ultimate goal is to classify tweets based on if they're from Breitbart or the Onion. The tweets aren't really in a format I can work with right now, so I will select a feature (the text of the tweet) that I want to use to predict the handle (my y variable). \n",
    "\n",
    "I'll be using [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) to vectorize the text data, initializing a bunch of classification models, training my data on a subset of tweets and then testing it on others to see how accurate the models are, and then pulling in tweets from accounts affiliated with Breitbart and The Onion to see how well the models do at predicting similar tweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://cdn.meme.am/cache/instances/folder666/65701666.jpg\">\n",
    "</p>\n",
    "</img>\n",
    "\n",
    "Sidenote: Allie Brosh is amazing and everyone should read [Hyperbole and a Half](https://hyperboleandahalf.blogspot.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#see image above\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocess the text of the tweets\n",
    "tfv = TfidfVectorizer(lowercase=True, strip_accents='unicode')\n",
    "X_all = tfv.fit_transform(all_tweets['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set up all the classifiers\n",
    "svc = SVC(kernel='linear', degree=4)\n",
    "rf = RandomForestClassifier(max_depth=10, n_estimators=500)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a function to do all the things\n",
    "#specifically: to split the data into training and testing sets, fit the model, predict whether or not a tweet in the \n",
    "#test set is Breitbart's or the Onion's\n",
    "#create a confusion matrix to see how well the model did in classifying tweets one way or the other\n",
    "#print out an accuracy score for how accurate the model was at predicting vs. what the tweet actually was\n",
    "# print out a classification report which shows how precise and sensitive the model is\n",
    "names = [\"is breitbart\", \"is onion\", \"pred breitbart\", \"predicted onion\"]\n",
    "def do_model(model, X, y, names):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    conmat = np.array(confusion_matrix(Y_test, Y_pred, labels=['Breitbart News','The Onion']))\n",
    "    confusion = pd.DataFrame(conmat, index=[names[0:2]],\n",
    "                         columns=[names[2:]])\n",
    "    print confusion\n",
    "    acc = accuracy_score(Y_test, Y_pred)\n",
    "    print \"accuracy score is\", acc\n",
    "    print(classification_report(Y_test, Y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              pred breitbart  predicted onion\n",
      "is breitbart              61                3\n",
      "is onion                  14               41\n",
      "accuracy score is 0.857142857143\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Breitbart News       0.81      0.95      0.88        64\n",
      "     The Onion       0.93      0.75      0.83        55\n",
      "\n",
      "   avg / total       0.87      0.86      0.85       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#first run the support vector machine classifier\n",
    "do_model(svc, X_all, all_tweets['handle'], names)\n",
    "\n",
    "#that's a pretty decent accuracy score, and the model seems to do quite a good job of predicting when something is \n",
    "#The Onion. Breitbart is apparently more difficult to tell apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              pred breitbart  predicted onion\n",
      "is breitbart              63                1\n",
      "is onion                  22               33\n",
      "accuracy score is 0.806722689076\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Breitbart News       0.74      0.98      0.85        64\n",
      "     The Onion       0.97      0.60      0.74        55\n",
      "\n",
      "   avg / total       0.85      0.81      0.80       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now the random forest classifier\n",
    "do_model(rf, X_all, all_tweets['handle'], names)\n",
    "#again, the model does a lot better at correctly predicting the Onion than at predicting Breitbart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              pred breitbart  predicted onion\n",
      "is breitbart              54               10\n",
      "is onion                  14               41\n",
      "accuracy score is 0.798319327731\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Breitbart News       0.79      0.84      0.82        64\n",
      "     The Onion       0.80      0.75      0.77        55\n",
      "\n",
      "   avg / total       0.80      0.80      0.80       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#how does a KNN do?\n",
    "do_model(knn, X_all, all_tweets['handle'], names)\n",
    "#that got slightly worse at predicting the Onion, but overall (going off the f1-score which measures the harmonic mean of precision and recall) \n",
    "#it does about as well as the random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              pred breitbart  predicted onion\n",
      "is breitbart              62                2\n",
      "is onion                  16               39\n",
      "accuracy score is 0.848739495798\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Breitbart News       0.79      0.97      0.87        64\n",
      "     The Onion       0.95      0.71      0.81        55\n",
      "\n",
      "   avg / total       0.87      0.85      0.85       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#and logistic regression\n",
    "do_model(lr, X_all, all_tweets['handle'], names)\n",
    "#whoo! That's a lot better than the random forest and the knn, but the SVC still ends up doing best. We'll use that for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how well top faring models do against random Onion Labs tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=4, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's start by training the model again (this time without training and testing because we're bringing in new tweets)\n",
    "tfidf = TfidfVectorizer(strip_accents='unicode',lowercase=True,stop_words='english')\n",
    "X_all = tfidf.fit_transform(all_tweets['text'])\n",
    "\n",
    "estimator = SVC(kernel='linear', degree=4, probability=True)\n",
    "estimator.fit(X_all, all_tweets['handle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Breitbart News' u'The Onion']\n"
     ]
    }
   ],
   "source": [
    "#double check classes \n",
    "print estimator.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19155199  0.80844801]\n",
      " [ 0.39333073  0.60666927]]\n"
     ]
    }
   ],
   "source": [
    "# Prep our source as vectors\n",
    "source_test = [\n",
    "    \"There are over 10,000 lakes in Minnesota, & there's a dare for every one of them. How many would you try?\",\n",
    "    \"If only Miles the interactive personality pump from @BP_America was on Twitter. Alas, this video will have to do http://onion.com/2gESxpN \"\n",
    "]\n",
    "\n",
    "#transform but DO NOT REFIT MODEL.\n",
    "X = tfidf.transform(source_test)\n",
    "\n",
    "#aaand predict!\n",
    "print estimator.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVC estimator correctly predicts that the tweets are probably from the Onion with a high degree of certainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just for additional kicks: Using TextBlob to conduct sentiment analysis on tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first create a new column in the dataframe that uses textblob to ...create a blob of text.\n",
    "all_tweets['blob'] = all_tweets['text'].map(TextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#next get the polarity of the textblob with a simple lambda function\n",
    "all_tweets['polarity'] = all_tweets['blob'].map(lambda x: x.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#and the same with the subjectivity of each textblob\n",
    "all_tweets['subjectivity'] = all_tweets['blob'].map(lambda x: x.sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>blob</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon Jan 30 16:53:00 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-01-30 11:54:31.522798</td>\n",
       "      <td>3</td>\n",
       "      <td>The Week In Pictures â€“ Week Of January 30, 201...</td>\n",
       "      <td>826110981025779712</td>\n",
       "      <td>(T, h, e,  , W, e, e, k,  , I, n,  , P, i, c, ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mon Jan 30 16:16:04 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-01-30 11:54:31.522808</td>\n",
       "      <td>42</td>\n",
       "      <td>Finland Aims To Be Tobacco-Free By 2020 https:...</td>\n",
       "      <td>826101685491752963</td>\n",
       "      <td>(F, i, n, l, a, n, d,  , A, i, m, s,  , T, o, ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon Jan 30 15:39:04 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-01-30 11:54:31.522812</td>\n",
       "      <td>233</td>\n",
       "      <td>Man Dying From Cancer Spends Last Good Day On ...</td>\n",
       "      <td>826092371255386113</td>\n",
       "      <td>(M, a, n,  , D, y, i, n, g,  , F, r, o, m,  , ...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Jan 30 14:48:06 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-01-30 11:54:31.522815</td>\n",
       "      <td>219</td>\n",
       "      <td>Parents Seize Creative Control Of 3rd-Grade Ar...</td>\n",
       "      <td>826079548089458690</td>\n",
       "      <td>(P, a, r, e, n, t, s,  , S, e, i, z, e,  , C, ...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mon Jan 30 13:57:03 +0000 2017</td>\n",
       "      <td>The Onion</td>\n",
       "      <td>2017-01-30 11:54:31.522818</td>\n",
       "      <td>395</td>\n",
       "      <td>Slow-Witted Conspiracy Theorist Convinced Gove...</td>\n",
       "      <td>826066701460582400</td>\n",
       "      <td>(S, l, o, w, -, W, i, t, t, e, d,  , C, o, n, ...</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at     handle                   mined_at  \\\n",
       "0  Mon Jan 30 16:53:00 +0000 2017  The Onion 2017-01-30 11:54:31.522798   \n",
       "1  Mon Jan 30 16:16:04 +0000 2017  The Onion 2017-01-30 11:54:31.522808   \n",
       "2  Mon Jan 30 15:39:04 +0000 2017  The Onion 2017-01-30 11:54:31.522812   \n",
       "3  Mon Jan 30 14:48:06 +0000 2017  The Onion 2017-01-30 11:54:31.522815   \n",
       "4  Mon Jan 30 13:57:03 +0000 2017  The Onion 2017-01-30 11:54:31.522818   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              3  The Week In Pictures â€“ Week Of January 30, 201...   \n",
       "1             42  Finland Aims To Be Tobacco-Free By 2020 https:...   \n",
       "2            233  Man Dying From Cancer Spends Last Good Day On ...   \n",
       "3            219  Parents Seize Creative Control Of 3rd-Grade Ar...   \n",
       "4            395  Slow-Witted Conspiracy Theorist Convinced Gove...   \n",
       "\n",
       "             tweet_id                                               blob  \\\n",
       "0  826110981025779712  (T, h, e,  , W, e, e, k,  , I, n,  , P, i, c, ...   \n",
       "1  826101685491752963  (F, i, n, l, a, n, d,  , A, i, m, s,  , T, o, ...   \n",
       "2  826092371255386113  (M, a, n,  , D, y, i, n, g,  , F, r, o, m,  , ...   \n",
       "3  826079548089458690  (P, a, r, e, n, t, s,  , S, e, i, z, e,  , C, ...   \n",
       "4  826066701460582400  (S, l, o, w, -, W, i, t, t, e, d,  , C, o, n, ...   \n",
       "\n",
       "   polarity  subjectivity  \n",
       "0      0.00      0.000000  \n",
       "1      0.00      0.000000  \n",
       "2      0.35      0.333333  \n",
       "3      0.50      1.000000  \n",
       "4     -0.40      0.700000  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to see if the columns came out okay\n",
    "all_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "handle               \n",
       "Breitbart News  count    192.000000\n",
       "                mean       0.045009\n",
       "                std        0.252172\n",
       "                min       -0.900000\n",
       "                25%        0.000000\n",
       "                50%        0.000000\n",
       "                75%        0.078958\n",
       "                max        1.000000\n",
       "The Onion       count    166.000000\n",
       "                mean       0.065367\n",
       "                std        0.207902\n",
       "                min       -0.457143\n",
       "                25%        0.000000\n",
       "                50%        0.000000\n",
       "                75%        0.136364\n",
       "                max        0.700000\n",
       "Name: polarity, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how do The Onion and Breitbart compare in terms of how polarizing their tweets are? \n",
    "all_tweets.groupby('handle').polarity.describe()\n",
    "#polarity just looks at the negativity and positivity of words (-1 being the most negative and 1 being the most positive), so it looks like on average, Breitbart uses more\n",
    "#positive language than the Onion. But for the most part, it looks like they both try to avoid language that's \n",
    "#super positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "handle               \n",
       "Breitbart News  count    192.000000\n",
       "                mean       0.242091\n",
       "                std        0.330249\n",
       "                min        0.000000\n",
       "                25%        0.000000\n",
       "                50%        0.000000\n",
       "                75%        0.500000\n",
       "                max        1.000000\n",
       "The Onion       count    166.000000\n",
       "                mean       0.269967\n",
       "                std        0.283788\n",
       "                min        0.000000\n",
       "                25%        0.000000\n",
       "                50%        0.200000\n",
       "                75%        0.500000\n",
       "                max        1.000000\n",
       "Name: subjectivity, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how do The Onion and Breitbart compare in terms of how subjective their tweets are? \n",
    "all_tweets.groupby('handle').subjectivity.describe()\n",
    "#subjectivity in textblob looks at words to see how subjective or objective they are (1 being the most subjective and 0 being the most objective)\n",
    "#given that both Breitbart and Onion market themselves as news sites (in one way or another), I'm not too surprised to see that\n",
    "#their mean subjectivity is pretty close to 0 (or being relatively objective)\n",
    "#it IS interesting to see tht both handles have tweeted something that rates as completely subjective, though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the chief conclusion here is that, while fake news and parody news are pretty similar in terms of how they construct their tweets (in order to resemble the objective construction that real news orgs use), machines are relatively good at predicting the probability of a tweet being one or the other.\n",
    "\n",
    "Of course, the next step here is to teach machines how to tell the difference between \"objective\" language that is steeped in hate and ...language that isn't."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
